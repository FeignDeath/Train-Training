{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0f2382",
   "metadata": {},
   "source": [
    "## Create the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05902e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from flatland.envs.line_generators import sparse_line_generator\n",
    "# In Flatland you can use custom observation builders and predicitors\n",
    "# Observation builders generate the observation needed by the controller\n",
    "# Preditctors can be used to do short time prediction which can help in avoiding conflicts in the network\n",
    "from flatland.envs.malfunction_generators import MalfunctionParameters, ParamMalfunctionGen\n",
    "from flatland.envs.observations import GlobalObsForRailEnv\n",
    "# First of all we import the Flatland rail environment\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.envs.rail_env import RailEnvActions\n",
    "from flatland.envs.rail_generators import sparse_rail_generator\n",
    "# We also include a renderer because we want to visualize what is going on in the environment\n",
    "from flatland.utils.rendertools import RenderTool, AgentRenderVariant\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b6547a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an introduction example for the Flatland 2.1.* version.\n",
    "# Changes and highlights of this version include\n",
    "# - Stochastic events (malfunctions)\n",
    "# - Different travel speeds for differet agents\n",
    "# - Levels are generated using a novel generator to reflect more realistic railway networks\n",
    "# - Agents start outside of the environment and enter at their own time\n",
    "# - Agents leave the environment after they have reached their goal\n",
    "\n",
    "# Use the new sparse_rail_generator to generate feasible network configurations with corresponding tasks\n",
    "# Training on simple small tasks is the best way to get familiar with the environment\n",
    "# We start by importing the necessary rail and schedule generators\n",
    "# The rail generator will generate the railway infrastructure\n",
    "# The schedule generator will assign tasks to all the agent within the railway network\n",
    "\n",
    "# The railway infrastructure can be built using any of the provided generators in env/rail_generators.py\n",
    "# Here we use the sparse_rail_generator with the following parameters\n",
    "\n",
    "DO_RENDERING = False\n",
    "\n",
    "width = 24  # With of map\n",
    "height = 24  # Height of map\n",
    "nr_trains = 1  # Number of trains that have an assigned task in the env\n",
    "cities_in_map = 2  # Number of cities where agents can start or end\n",
    "seed = 14  # Random seed - 14\n",
    "grid_distribution_of_cities = False  # Type of city distribution, if False cities are randomly placed\n",
    "max_rails_between_cities = 2  # Max number of tracks allowed between cities. This is number of entry point to a city\n",
    "max_rail_in_cities = 2  # Max number of parallel tracks within a city, representing a realistic trainstation\n",
    "\n",
    "rail_generator = sparse_rail_generator(max_num_cities=cities_in_map,\n",
    "                                       seed=seed,\n",
    "                                       grid_mode=grid_distribution_of_cities,\n",
    "                                       max_rails_between_cities=max_rails_between_cities,\n",
    "                                       max_rail_pairs_in_city=max_rail_in_cities,\n",
    "                                       )\n",
    "\n",
    "# rail_generator = SparseRailGen(max_num_cities=cities_in_map,\n",
    "#                                       seed=seed,\n",
    "#                                       grid_mode=grid_distribution_of_cities,\n",
    "#                                       max_rails_between_cities=max_rails_between_cities,\n",
    "#                                       max_rails_in_city=max_rail_in_cities,\n",
    "#                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4642a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schedule generator can make very basic schedules with a start point, end point and a speed profile for each agent.\n",
    "# The speed profiles can be adjusted directly as well as shown later on. We start by introducing a statistical\n",
    "# distribution of speed profiles\n",
    "\n",
    "# Different agent types (trains) with different speeds.\n",
    "# speed_ration_map = {1.: 0.25,  # Fast passenger train\n",
    "#                     1. / 2.: 0.25,  # Fast freight train\n",
    "#                     1. / 3.: 0.25,  # Slow commuter train\n",
    "#                     1. / 4.: 0.25}  # Slow freight train\n",
    "\n",
    "speed_ration_map = {1: 1.0}\n",
    "\n",
    "# We can now initiate the schedule generator with the given speed profiles\n",
    "\n",
    "line_generator = sparse_line_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b60b437",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?????\n",
      "6 6\n",
      "?????\n",
      "7 6\n",
      "?????\n",
      "8 6\n",
      "?????\n",
      "9 6\n",
      "?????\n",
      "10 6\n",
      "?????\n",
      "11 6\n",
      "?????\n",
      "11 5\n",
      "?????\n",
      "11 4\n",
      "?????\n",
      "11 3\n",
      "?????\n",
      "11 2\n",
      "?????\n",
      "11 1\n",
      "?????\n",
      "10 1\n",
      "?????\n",
      "9 1\n",
      "?????\n",
      "8 1\n",
      "?????\n",
      "7 1\n",
      "?????\n",
      "6 1\n",
      "?????\n",
      "5 1\n",
      "?????\n",
      "4 1\n",
      "?????\n",
      "3 1\n",
      "?????\n",
      "2 1\n",
      "?????\n",
      "1 1\n",
      "?????\n",
      "1 2\n",
      "?????\n",
      "1 3\n",
      "?????\n",
      "1 4\n",
      "?????\n",
      "1 5\n",
      "?????\n",
      "1 6\n",
      "?????\n",
      "2 6\n",
      "?????\n",
      "3 6\n",
      "?????\n",
      "4 6\n",
      "?????\n",
      "5 6\n",
      "?????\n",
      "3 7\n",
      "?????\n",
      "4 7\n",
      "?????\n",
      "4 6\n",
      "?????\n",
      "5 7\n",
      "?????\n",
      "6 7\n",
      "?????\n",
      "7 7\n",
      "?????\n",
      "8 7\n",
      "?????\n",
      "9 7\n",
      "?????\n",
      "9 6\n",
      "?????\n",
      "12 6\n",
      "?????\n",
      "12 5\n",
      "?????\n",
      "13 5\n",
      "?????\n",
      "13 4\n",
      "?????\n",
      "13 3\n",
      "?????\n",
      "13 2\n",
      "?????\n",
      "13 1\n",
      "?????\n",
      "14 1\n",
      "?????\n",
      "15 1\n",
      "?????\n",
      "16 1\n",
      "?????\n",
      "17 1\n",
      "?????\n",
      "18 1\n",
      "?????\n",
      "19 1\n",
      "?????\n",
      "20 1\n",
      "?????\n",
      "21 1\n",
      "?????\n",
      "22 1\n",
      "?????\n",
      "23 1\n",
      "?????\n",
      "23 2\n",
      "?????\n",
      "23 3\n",
      "?????\n",
      "23 4\n",
      "?????\n",
      "23 5\n",
      "?????\n",
      "23 6\n",
      "?????\n",
      "22 6\n",
      "?????\n",
      "21 6\n",
      "?????\n",
      "21 7\n",
      "?????\n",
      "20 7\n",
      "?????\n",
      "20 6\n",
      "?????\n",
      "19 6\n",
      "?????\n",
      "18 6\n",
      "?????\n",
      "17 6\n",
      "?????\n",
      "16 6\n",
      "?????\n",
      "16 7\n",
      "?????\n",
      "15 7\n",
      "?????\n",
      "15 6\n",
      "?????\n",
      "14 6\n",
      "?????\n",
      "13 6\n",
      "?????\n",
      "12 6\n",
      "?????\n",
      "11 6\n",
      "?????\n",
      "11 7\n",
      "?????\n",
      "12 7\n",
      "?????\n",
      "13 7\n",
      "?????\n",
      "14 7\n",
      "?????\n",
      "15 7\n",
      "?????\n",
      "16 7\n",
      "?????\n",
      "16 6\n",
      "?????\n",
      "17 6\n",
      "?????\n",
      "18 6\n",
      "?????\n",
      "19 6\n",
      "?????\n",
      "20 6\n",
      "?????\n",
      "21 6\n",
      "?????\n",
      "22 6\n",
      "?????\n",
      "23 6\n",
      "?????\n",
      "23 5\n",
      "?????\n",
      "23 4\n",
      "?????\n",
      "23 3\n",
      "?????\n",
      "23 2\n",
      "?????\n",
      "23 1\n",
      "?????\n",
      "22 1\n",
      "?????\n",
      "21 1\n",
      "?????\n",
      "20 1\n",
      "?????\n",
      "19 1\n",
      "?????\n",
      "18 1\n",
      "?????\n",
      "17 1\n",
      "?????\n",
      "16 1\n",
      "?????\n",
      "15 1\n",
      "?????\n",
      "14 1\n",
      "?????\n",
      "13 1\n",
      "?????\n",
      "13 2\n",
      "?????\n",
      "13 3\n",
      "?????\n",
      "13 4\n",
      "?????\n",
      "13 5\n",
      "?????\n",
      "12 5\n",
      "?????\n",
      "12 6\n",
      "?????\n",
      "20 7\n",
      "?????\n",
      "21 7\n",
      "?????\n",
      "21 6\n",
      "?????\n",
      "22 7\n",
      "?????\n",
      "23 7\n",
      "?????\n",
      "23 8\n",
      "?????\n",
      "23 9\n",
      "?????\n",
      "23 10\n",
      "?????\n",
      "23 11\n",
      "?????\n",
      "22 11\n",
      "?????\n",
      "21 11\n",
      "?????\n",
      "20 11\n",
      "?????\n",
      "19 11\n",
      "?????\n",
      "18 11\n",
      "?????\n",
      "17 11\n",
      "?????\n",
      "16 11\n",
      "?????\n",
      "15 11\n",
      "?????\n",
      "14 11\n",
      "?????\n",
      "13 11\n",
      "?????\n",
      "13 10\n",
      "?????\n",
      "13 9\n",
      "?????\n",
      "13 8\n",
      "?????\n",
      "12 8\n",
      "?????\n",
      "11 8\n",
      "?????\n",
      "11 7\n",
      "?????\n",
      "11 6\n",
      "?????\n",
      "17 7\n",
      "?????\n",
      "6 6\n",
      "?????\n",
      "5 6\n",
      "?????\n",
      "4 6\n",
      "?????\n",
      "4 7\n",
      "?????\n",
      "3 7\n",
      "?????\n",
      "3 6\n",
      "?????\n",
      "2 6\n",
      "?????\n",
      "1 6\n",
      "?????\n",
      "1 5\n",
      "?????\n",
      "1 4\n",
      "?????\n",
      "1 3\n",
      "?????\n",
      "1 2\n",
      "?????\n",
      "1 1\n",
      "?????\n",
      "2 1\n",
      "?????\n",
      "3 1\n",
      "?????\n",
      "4 1\n",
      "?????\n",
      "5 1\n",
      "?????\n",
      "6 1\n",
      "?????\n",
      "7 1\n",
      "?????\n",
      "8 1\n",
      "?????\n",
      "9 1\n",
      "?????\n",
      "10 1\n",
      "?????\n",
      "11 1\n",
      "?????\n",
      "11 2\n",
      "?????\n",
      "11 3\n",
      "?????\n",
      "11 4\n",
      "?????\n",
      "11 5\n",
      "?????\n",
      "11 6\n",
      "?????\n",
      "11 7\n",
      "?????\n",
      "12 7\n",
      "?????\n",
      "13 7\n",
      "?????\n",
      "14 7\n",
      "?????\n",
      "15 7\n",
      "?????\n",
      "16 7\n",
      "?????\n",
      "16 6\n",
      "?????\n",
      "17 6\n",
      "?????\n",
      "18 6\n",
      "?????\n",
      "19 6\n",
      "?????\n",
      "20 6\n",
      "?????\n",
      "21 6\n",
      "?????\n",
      "22 6\n",
      "?????\n",
      "23 6\n",
      "?????\n",
      "23 5\n",
      "?????\n",
      "23 4\n",
      "?????\n",
      "23 3\n",
      "?????\n",
      "23 2\n",
      "?????\n",
      "23 1\n",
      "?????\n",
      "22 1\n",
      "?????\n",
      "21 1\n",
      "?????\n",
      "20 1\n",
      "?????\n",
      "19 1\n",
      "?????\n",
      "18 1\n",
      "?????\n",
      "17 1\n",
      "?????\n",
      "16 1\n",
      "?????\n",
      "15 1\n",
      "?????\n",
      "14 1\n",
      "?????\n",
      "13 1\n",
      "?????\n",
      "13 2\n",
      "?????\n",
      "13 3\n",
      "?????\n",
      "13 4\n",
      "?????\n",
      "13 5\n",
      "?????\n",
      "12 5\n",
      "?????\n",
      "12 6\n",
      "?????\n",
      "11 6\n",
      "?????\n",
      "10 6\n",
      "?????\n",
      "9 6\n",
      "?????\n",
      "9 7\n",
      "?????\n",
      "8 7\n",
      "?????\n",
      "8 6\n",
      "?????\n",
      "7 6\n",
      "?????\n",
      "7 7\n",
      "?????\n",
      "6 7\n",
      "?????\n",
      "5 7\n",
      "?????\n",
      "4 7\n",
      "?????\n",
      "8 6\n",
      "?????\n",
      "20 7\n",
      "?????\n",
      "21 7\n",
      "?????\n",
      "21 6\n",
      "?????\n",
      "22 7\n",
      "?????\n",
      "23 7\n",
      "?????\n",
      "23 8\n",
      "?????\n",
      "23 9\n",
      "?????\n",
      "23 10\n",
      "?????\n",
      "23 11\n",
      "?????\n",
      "22 11\n",
      "?????\n",
      "21 11\n",
      "?????\n",
      "20 11\n",
      "?????\n",
      "19 11\n",
      "?????\n",
      "18 11\n",
      "?????\n",
      "17 11\n",
      "?????\n",
      "16 11\n",
      "?????\n",
      "15 11\n",
      "?????\n",
      "14 11\n",
      "?????\n",
      "13 11\n",
      "?????\n",
      "13 10\n",
      "?????\n",
      "13 9\n",
      "?????\n",
      "13 8\n",
      "?????\n",
      "12 8\n",
      "?????\n",
      "11 8\n",
      "?????\n",
      "11 7\n",
      "?????\n",
      "11 6\n",
      "?????\n",
      "11 5\n",
      "?????\n",
      "11 4\n",
      "?????\n",
      "11 3\n",
      "?????\n",
      "11 2\n",
      "?????\n",
      "11 1\n",
      "?????\n",
      "10 1\n",
      "?????\n",
      "9 1\n",
      "?????\n",
      "8 1\n",
      "?????\n",
      "7 1\n",
      "?????\n",
      "6 1\n",
      "?????\n",
      "5 1\n",
      "?????\n",
      "4 1\n",
      "?????\n",
      "3 1\n",
      "?????\n",
      "2 1\n",
      "?????\n",
      "1 1\n",
      "?????\n",
      "1 2\n",
      "?????\n",
      "1 3\n",
      "?????\n",
      "1 4\n",
      "?????\n",
      "1 5\n",
      "?????\n",
      "1 6\n",
      "?????\n",
      "2 6\n",
      "?????\n",
      "3 6\n",
      "?????\n",
      "4 6\n",
      "?????\n",
      "5 6\n",
      "?????\n",
      "6 6\n",
      "?????\n",
      "7 6\n",
      "?????\n",
      "8 6\n",
      "?????\n",
      "9 6\n",
      "?????\n",
      "10 6\n",
      "?????\n",
      "11 6\n",
      "?????\n",
      "12 6\n",
      "?????\n",
      "12 5\n",
      "?????\n",
      "13 5\n",
      "?????\n",
      "13 4\n",
      "?????\n",
      "13 3\n",
      "?????\n",
      "13 2\n",
      "?????\n",
      "13 1\n",
      "?????\n",
      "14 1\n",
      "?????\n",
      "15 1\n",
      "?????\n",
      "16 1\n",
      "?????\n",
      "17 1\n",
      "?????\n",
      "18 1\n",
      "?????\n",
      "19 1\n",
      "?????\n",
      "20 1\n",
      "?????\n",
      "21 1\n",
      "?????\n",
      "22 1\n",
      "?????\n",
      "23 1\n",
      "?????\n",
      "23 2\n",
      "?????\n",
      "23 3\n",
      "?????\n",
      "23 4\n",
      "?????\n",
      "23 5\n",
      "?????\n",
      "23 6\n",
      "?????\n",
      "22 6\n",
      "?????\n",
      "21 6\n",
      "?????\n",
      "21 7\n",
      "?????\n",
      "20 7\n",
      "?????\n",
      "20 6\n",
      "?????\n",
      "19 6\n",
      "?????\n",
      "18 6\n",
      "?????\n",
      "17 6\n",
      "?????\n",
      "16 6\n",
      "?????\n",
      "16 7\n",
      "?????\n",
      "15 7\n",
      "?????\n",
      "15 6\n",
      "?????\n",
      "14 6\n",
      "?????\n",
      "13 6\n",
      "?????\n",
      "12 6\n",
      "?????\n",
      "14 7\n",
      "?????\n",
      "13 7\n",
      "?????\n",
      "12 7\n",
      "?????\n",
      "11 7\n",
      "?????\n",
      "15 6\n",
      "?????\n",
      "19 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanmurphy/opt/anaconda3/lib/python3.8/site-packages/flatland/envs/rail_generators.py:350: UserWarning: Could not set all required cities! Created 1/2\n",
      "  warnings.warn(city_warning)\n",
      "/Users/ryanmurphy/opt/anaconda3/lib/python3.8/site-packages/flatland/envs/rail_generators.py:262: UserWarning: [WARNING] Changing to Grid mode to place at least 2 cities.\n",
      "  warnings.warn(\"[WARNING] Changing to Grid mode to place at least 2 cities.\")\n"
     ]
    }
   ],
   "source": [
    "# Custom observation builder without predictor\n",
    "observation_builder = GlobalObsForRailEnv()\n",
    "\n",
    "# Custom observation builder with predictor, uncomment line below if you want to try this one\n",
    "# observation_builder = TreeObsForRailEnv(max_depth=2, predictor=ShortestPathPredictorForRailEnv())\n",
    "\n",
    "# Construct the enviornment with the given observation, generataors, predictors, and stochastic data\n",
    "env = RailEnv(width=width,\n",
    "              height=height,\n",
    "              rail_generator=rail_generator,\n",
    "              line_generator=line_generator,\n",
    "              number_of_agents=nr_trains,\n",
    "              obs_builder_object=observation_builder,\n",
    "              remove_agents_at_target=True)\n",
    "env.reset()\n",
    "\n",
    "# Initiate the renderer\n",
    "env_renderer = None\n",
    "if DO_RENDERING:\n",
    "    env_renderer = RenderTool(env,\n",
    "                              agent_render_variant=AgentRenderVariant.ONE_STEP_BEHIND,\n",
    "                              show_debug=False,\n",
    "                              screen_height=600,  # Adjust these parameters to fit your resolution\n",
    "                              screen_width=800)  # Adjust these parameters to fit your resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78f920da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rail grid array to Clingo string\n",
    "class clingo_grid():\n",
    "    \"\"\"representing the array of a Flatland map in a way that clingo can process\"\"\"\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        rail_map = env.rail.grid\n",
    "        self.clingo_str = \"\"\n",
    "        self.mapping = {}\n",
    "        \n",
    "        row_num = len(rail_map) - 1\n",
    "        for row in rail_map:\n",
    "            for col,cval in enumerate(row):\n",
    "                self.clingo_str += \"cell(({},{}), {}). \".format(col+0,row_num+0,cval)\n",
    "                self.mapping[(col,row_num)] = cval\n",
    "            row_num -= 1\n",
    "\n",
    "        dir_map = {0:\"n\", 1:\"e\", 2:\"s\", 3:\"w\"}\n",
    "        self.clingo_str += \"start(cell({},{}),dir({})). \".format(env.agents[0].initial_position[1], env.agents[0].initial_position[0], dir_map[env.agents[0].initial_direction])\n",
    "        self.clingo_str += \"end(cell({},{})). \".format(env.agents[0].target[1], env.agents[0].target[0])\n",
    "\t\n",
    "\n",
    "# generate environments\n",
    "num_environments = 1 #only generating one\n",
    "\n",
    "for envir in range(num_environments):\n",
    "    #current_env = build_env(*parameters, envir) #set envir as seed value\n",
    "    current_env = env\n",
    "\n",
    "    # save entire environment -- BUG\n",
    "    # current_env.save('save_test')\n",
    "\n",
    "    # render an image\n",
    "    env_renderer = RenderTool(current_env, gl=\"PILSVG\", )\n",
    "    env_renderer.render_env(show=True, show_observations=False, show_predictions=False)\n",
    "    env_renderer.gl.save_image('./test_envs/env_{}.png'.format(envir))\n",
    "    env_renderer.reset()\n",
    "\n",
    "    # save rail grid\n",
    "    #np.savetxt('./test_envs/env_'+str(envir), current_env, fmt = '% 4d')\n",
    "    clingo = clingo_grid(current_env)\n",
    "    f = open('./test_envs/env_'+str(envir), 'w')\n",
    "    f.write(clingo.clingo_str)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c6b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.agents[0].initial_position, env.agents[0].target, env.agents[0].initial_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f839b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually determine start and end\n",
    "#env.agents[0].initial_position = (1,9)\n",
    "#env.agents[0].target = (7,15)\n",
    "#env.agents[0].initial_direction = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12663877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from flatland.utils.rendertools import RenderTool\n",
    "env_renderer = RenderTool(env, gl=\"PILSVG\", )\n",
    "env_renderer.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d9a0485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to enter with all of these agents at the same time\n",
    "action_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede3236",
   "metadata": {},
   "source": [
    "## Find a path using Clingo\n",
    "\n",
    "Shouldn't be able to do actions once they hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c93cac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "%%clingo 1 - test_envs/env_0 transitions.lp actions.lp --outf=2\n",
    "\n",
    "% ENCODING\n",
    "maxTime(54).\n",
    "\n",
    "at(cell(X0,Y0), D, 0) :- start(cell(X0,Y0), dir(D)).                          % determine first cell\n",
    "do(f,0).                                                                      % first move is always forward\n",
    "\n",
    "{ do(A,T) : move(A) } = 1 :- maxTime(M), T=1..M.                              % chose one move per time step\n",
    "    \n",
    ":- do(A,T), at(cell(X,Y), D, T), cell((X,Y), Type), not type(Type, (D,A)).    % keep only legal actions\n",
    "    \n",
    "at(cell(X1,Y1), ResultingDir, T) :- do(A,T-1), at(cell(X0,Y0), D, T-1), offset((D,A), (DX,DY), ResultingDir), X1=X0+DX, Y1=Y0+DY.    % determine resulting cells\n",
    "\n",
    ":- end(cell(X,Y)), not at(cell(X,Y), _, _).                                   % must reach goal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a4483e",
   "metadata": {},
   "source": [
    "### Save the output to an auxiliary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef46f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output.json', 'w') as f:\n",
    "     f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cea552d",
   "metadata": {},
   "source": [
    "### Read actions from output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "952c5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./output.json', 'r') as f:\n",
    "    file = json.load(f)\n",
    "    \n",
    "try:\n",
    "    actions = file['Call'][0]['Witnesses'][0]['Value']\n",
    "except KeyError as e:\n",
    "    print('\\n\\nError:\\n\\nThe model is unsatisfiable.  Try increasing the maximum number of steps.\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0faad948",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = []\n",
    "for act in actions:\n",
    "    a = re.match(\"[a-z_]*\", act).group(0).upper()\n",
    "    t = re.match(\".*\\((\\d+)\\)\", act).group(1)\n",
    "    action_list.append((int(t),a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0922e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#action_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd10d9",
   "metadata": {},
   "source": [
    "### Sort actions into the correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5103919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take these and keep just the actions in the right (sorted) order\n",
    "actions = []\n",
    "for tup in sorted(action_list):\n",
    "    actions.append(tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "503c1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_actions = int(sorted(action_list)[-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2160f49",
   "metadata": {},
   "source": [
    "### Create a `ClingoAgent` in Flatland\n",
    "\n",
    "Benefit to inheret?  Ask Michel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e221b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first thing we notice is that some agents don't have feasible paths to their target.\n",
    "# We first look at the map we have created\n",
    "\n",
    "# nv_renderer.render_env(show=True)\n",
    "# time.sleep(2)\n",
    "# Import your own Agent or use RLlib to train agents on Flatland\n",
    "\n",
    "# As an example we use a random agent instead\n",
    "class ClingoAgent:\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "        :param state: input is the observation of the agent\n",
    "        :return: returns an action\n",
    "        \"\"\"\n",
    "        mapping = {\"MOVE_FORWARD\":RailEnvActions.MOVE_FORWARD, \"MOVE_RIGHT\":RailEnvActions.MOVE_RIGHT, \"MOVE_LEFT\":RailEnvActions.MOVE_LEFT, \"STOP_MOVING\":RailEnvActions.STOP_MOVING}\n",
    "        print(state, mapping[actions[state]])\n",
    "        return mapping[actions[state]]\n",
    "        \n",
    "\n",
    "    def step(self, memories):\n",
    "        \"\"\"\n",
    "        Step function to improve agent by adjusting policy given the observations\n",
    "\n",
    "        :param memories: SARS Tuple to be\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def save(self, filename):\n",
    "        # Store the current policy\n",
    "        return\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load a policy\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686408b",
   "metadata": {},
   "source": [
    "### Render a visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29bf4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Agents in the environment have to solve the following tasks: \n",
      "\n",
      "The agent with index 0 has the task to go from its initial position (6, 6), facing in the direction 0 to its target at (18, 7).\n",
      "\n",
      " Their current statuses are:\n",
      "============================\n",
      "Agent 0 status is: TrainState.WAITING with its current position being None\n",
      "\n",
      " The following agents have the same initial position:\n",
      "=====================================================\n",
      "\n",
      " This happened when all tried to enter at the same time:\n",
      "========================================================\n",
      "\n",
      " The speed information of the agents are:\n",
      "=========================================\n",
      "Agent 0 speed is: 1.00 with the current fractional position being 0/0\n",
      "\n",
      " The malfunction data of the agents are:\n",
      "========================================\n",
      "Agent 0 is OK = False\n",
      "0 RailEnvActions.MOVE_FORWARD\n",
      "\n",
      " The following agents can register an action:\n",
      "========================================\n",
      "Agent 0 needs to submit an action.\n",
      "\n",
      "Start episode...\n",
      "0 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 0\t Score = 0\n",
      "1 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 1\t Score = 0\n",
      "2 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 2\t Score = 0\n",
      "3 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 3\t Score = 0\n",
      "4 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 4\t Score = 0\n",
      "5 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 5\t Score = 0\n",
      "6 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 6\t Score = 0\n",
      "7 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 7\t Score = 0\n",
      "8 RailEnvActions.MOVE_RIGHT\n",
      "Episode: Steps 8\t Score = 0\n",
      "9 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 9\t Score = 0\n",
      "10 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 10\t Score = 0\n",
      "11 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 11\t Score = 0\n",
      "12 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 12\t Score = 0\n",
      "13 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 13\t Score = 0\n",
      "14 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 14\t Score = 0\n",
      "15 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 15\t Score = 0\n",
      "16 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 16\t Score = 0\n",
      "17 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 17\t Score = 0\n",
      "18 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 18\t Score = 0\n",
      "19 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 19\t Score = 0\n",
      "20 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 20\t Score = 0\n",
      "21 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 21\t Score = 0\n",
      "22 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 22\t Score = 0\n",
      "23 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 23\t Score = 0\n",
      "24 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 24\t Score = 0\n",
      "25 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 25\t Score = 0\n",
      "26 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 26\t Score = 0\n",
      "27 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 27\t Score = 0\n",
      "28 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 28\t Score = 0\n",
      "29 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 29\t Score = 0\n",
      "30 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 30\t Score = 0\n",
      "31 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 31\t Score = 0\n",
      "32 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 32\t Score = 0\n",
      "33 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 33\t Score = 0\n",
      "34 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 34\t Score = 0\n",
      "35 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 35\t Score = 0\n",
      "36 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 36\t Score = 0\n",
      "37 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 37\t Score = 0\n",
      "38 RailEnvActions.MOVE_LEFT\n",
      "Episode: Steps 38\t Score = 0\n",
      "39 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 39\t Score = 0\n",
      "40 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 40\t Score = 0\n",
      "41 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 41\t Score = 0\n",
      "42 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 42\t Score = 0\n",
      "43 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 43\t Score = 0\n",
      "44 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 44\t Score = 0\n",
      "45 RailEnvActions.MOVE_RIGHT\n",
      "Episode: Steps 45\t Score = 0\n",
      "46 RailEnvActions.MOVE_LEFT\n",
      "Episode: Steps 46\t Score = 0\n",
      "47 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 47\t Score = 0\n",
      "48 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 48\t Score = 0\n",
      "49 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 49\t Score = 0\n",
      "50 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 50\t Score = 0\n",
      "51 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 51\t Score = 0\n",
      "52 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 52\t Score = 0\n",
      "53 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 53\t Score = 0\n",
      "54 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 54\t Score = 0\n",
      "55 RailEnvActions.MOVE_FORWARD\n",
      "Episode: Steps 55\t Score = 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent with the parameters corresponding to the environment and observation_builder\n",
    "controller = ClingoAgent(218, env.action_space[0])\n",
    "\n",
    "# We start by looking at the information of each agent\n",
    "# We can see the task assigned to the agent by looking at\n",
    "print(\"\\n Agents in the environment have to solve the following tasks: \\n\")\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    print(\n",
    "        \"The agent with index {} has the task to go from its initial position {}, facing in the direction {} to its target at {}.\".format(\n",
    "            agent_idx, agent.initial_position, agent.direction, agent.target))\n",
    "\n",
    "# The agent will always have a status indicating if it is currently present in the environment or done or active\n",
    "# For example we see that agent with index 0 is currently not active\n",
    "print(\"\\n Their current statuses are:\")\n",
    "print(\"============================\")\n",
    "\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    print(\"Agent {} status is: {} with its current position being {}\".format(agent_idx, str(agent.state),\n",
    "                                                                             str(agent.position)))\n",
    "\n",
    "# The agent needs to take any action [1,2,3] except do_nothing or stop to enter the level\n",
    "# If the starting cell is free they will enter the level\n",
    "# If multiple agents want to enter the same cell at the same time the lower index agent will enter first.\n",
    "\n",
    "# Let's check if there are any agents with the same start location\n",
    "agents_with_same_start = set()\n",
    "print(\"\\n The following agents have the same initial position:\")\n",
    "print(\"=====================================================\")\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    for agent_2_idx, agent2 in enumerate(env.agents):\n",
    "        if agent_idx != agent_2_idx and agent.initial_position == agent2.initial_position:\n",
    "            print(\"Agent {} as the same initial position as agent {}\".format(agent_idx, agent_2_idx))\n",
    "            agents_with_same_start.add(agent_idx)\n",
    "\n",
    "# Lets try to enter with all of these agents at the same time\n",
    "action_dict = dict()\n",
    "\n",
    "for agent_id in agents_with_same_start:\n",
    "    action_dict[agent_id] = 1  # Try to move with the agents\n",
    "\n",
    "# Do a step in the environment to see what agents entered:\n",
    "env.step(action_dict)\n",
    "\n",
    "# Current state and position of the agents after all agents with same start position tried to move\n",
    "print(\"\\n This happened when all tried to enter at the same time:\")\n",
    "print(\"========================================================\")\n",
    "for agent_id in agents_with_same_start:\n",
    "    print(\n",
    "        \"Agent {} status is: {} with the current position being {}.\".format(\n",
    "            agent_id, str(env.agents[agent_id].state),\n",
    "            str(env.agents[agent_id].position)))\n",
    "\n",
    "# As you see only the agents with lower indexes moved. As soon as the cell is free again the agents can attempt\n",
    "# to start again.\n",
    "\n",
    "# You will also notice, that the agents move at different speeds once they are on the rail.\n",
    "# The agents will always move at full speed when moving, never a speed inbetween.\n",
    "# The fastest an agent can go is 1, meaning that it moves to the next cell at every time step\n",
    "# All slower speeds indicate the fraction of a cell that is moved at each time step\n",
    "# Lets look at the current speed data of the agents:\n",
    "\n",
    "print(\"\\n The speed information of the agents are:\")\n",
    "print(\"=========================================\")\n",
    "\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    print(\n",
    "        \"Agent {} speed is: {:.2f} with the current fractional position being {}/{}\".format(\n",
    "            agent_idx, agent.speed_counter.speed, agent.speed_counter.counter, agent.speed_counter.max_count))\n",
    "\n",
    "# New the agents can also have stochastic malfunctions happening which will lead to them being unable to move\n",
    "# for a certain amount of time steps. The malfunction data of the agents can easily be accessed as follows\n",
    "print(\"\\n The malfunction data of the agents are:\")\n",
    "print(\"========================================\")\n",
    "\n",
    "for agent_idx, agent in enumerate(env.agents):\n",
    "    print(\n",
    "        \"Agent {} is OK = {}\".format(\n",
    "            agent_idx, agent.malfunction_handler.in_malfunction))\n",
    "\n",
    "# Now that you have seen these novel concepts that were introduced you will realize that agents don't need to take\n",
    "# an action at every time step as it will only change the outcome when actions are chosen at cell entry.\n",
    "# Therefore the environment provides information about what agents need to provide an action in the next step.\n",
    "# You can access this in the following way.\n",
    "\n",
    "# Chose an action for each agent\n",
    "for a in range(env.get_num_agents()):\n",
    "    action = controller.act(0)\n",
    "    action_dict.update({a: action})\n",
    "# Do the environment step\n",
    "observations, rewards, dones, information = env.step(action_dict)\n",
    "print(\"\\n The following agents can register an action:\")\n",
    "print(\"========================================\")\n",
    "for info in information['action_required']:\n",
    "    print(\"Agent {} needs to submit an action.\".format(info))\n",
    "\n",
    "# We recommend that you monitor the malfunction data and the action required in order to optimize your training\n",
    "# and controlling code.\n",
    "\n",
    "# Let us now look at an episode playing out with random actions performed\n",
    "\n",
    "print(\"\\nStart episode...\")\n",
    "\n",
    "# Reset the rendering system\n",
    "if env_renderer is not None:\n",
    "    env_renderer.reset()\n",
    "\n",
    "# Here you can also further enhance the provided observation by means of normalization\n",
    "# See training navigation example in the baseline repository\n",
    "\n",
    "\n",
    "score = 0\n",
    "# Run episode\n",
    "frame_step = 0\n",
    "\n",
    "os.makedirs(\"tmp/frames\", exist_ok=True)\n",
    "\n",
    "for step in range(max_actions+1):\n",
    "    # Chose an action for each agent in the environment\n",
    "    for a in range(env.get_num_agents()):\n",
    "        #action = controller.act(observations[a])\n",
    "        action = controller.act(step)\n",
    "        action_dict.update({a: action})\n",
    "\n",
    "    # Environment step which returns the observations for all agents, their corresponding\n",
    "    # reward and whether their are done\n",
    "\n",
    "    next_obs, all_rewards, done, _ = env.step(action_dict)\n",
    "\n",
    "    if env_renderer is not None:\n",
    "        env_renderer.render_env(show=True, show_observations=False, show_predictions=False)\n",
    "        env_renderer.gl.save_image('tmp/frames/flatland_frame_{:04d}.png'.format(step))\n",
    "        env_renderer.reset()\n",
    "    \n",
    "    done['__all__'] = False\n",
    "\n",
    "#    frame_step += 1\n",
    "    # Update replay buffer and train agent\n",
    "#     for a in range(env.get_num_agents()):\n",
    "#         controller.step((observations[a], action_dict[a], all_rewards[a], next_obs[a], done[a]))\n",
    "#         score += all_rewards[a]\n",
    "\n",
    "#     observations = next_obs.copy()\n",
    "#     if done['__all__']:\n",
    "#         print('all are done')\n",
    "#         break\n",
    "        \n",
    "    print('Episode: Steps {}\\t Score = {}'.format(step, score))\n",
    "\n",
    "# close the renderer / rendering window\n",
    "if env_renderer is not None:\n",
    "    env_renderer.close_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8037a49",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
